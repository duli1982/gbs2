[
  {
    "id": "1-01",
    "stage": 1,
    "stageTitle": "Intake & Role Passport",
    "type": "intake",
    "title": "Intake Clarifier",
    "preview": "Transform messy hiring manager notes into structured role requirements with binary must-haves.",
    "content": "You are a senior recruiting strategist. I will provide you with raw intake notes from a hiring manager. Your job is to convert these into a structured Role Passport.\n\nExtract and organize:\n1. MUST-HAVES (binary yes/no \u2014 no 'nice to haves' disguised as musts)\n2. DEALBREAKERS (what immediately disqualifies)\n3. LOCATION REALITY (onsite requirements, relocation expectations, timezone needs)\n4. COMPENSATION RANGE (what is actually approved, not aspirational)\n5. KEY MOTIVATORS (what would attract the right person to this role)\n6. EVIDENCE REQUIREMENTS (what proof do we need to see for each must-have)\n\nFor any vague or missing information, flag it explicitly as: [CLARIFICATION NEEDED: specific question]\n\nDo NOT fill in assumptions. If something is unclear, say so.\n\nHere are the intake notes:\n[PASTE INTAKE NOTES HERE]",
    "usageNotes": "Use this at the very start of every new role. Paste the HM's email, Slack message, or meeting notes directly. The output becomes your Role Passport draft.",
    "tier": "Starter"
  },
  {
    "id": "1-02",
    "stage": 1,
    "stageTitle": "Intake & Role Passport",
    "type": "execution",
    "title": "Calibration Pack Generator",
    "preview": "Generate 3 strong-fit and 3 poor-fit profile sketches based on role requirements.",
    "content": "Based on the following role requirements, generate a calibration pack to align the recruiting team and hiring manager.\n\nCreate:\n\nSTRONG FIT PROFILES (3):\nFor each, describe:\n- Background summary (2-3 sentences)\n- Why they match the must-haves (with specific evidence you'd expect to see)\n- Potential risk and how you'd validate it\n\nPOOR FIT PROFILES (3):\nFor each, describe:\n- Background summary (2-3 sentences)\n- Why they look good on the surface but would fail\n- The specific gap or mismatch\n\nRole requirements:\n[PASTE ROLE PASSPORT HERE]",
    "usageNotes": "Share the calibration pack with the HM and your team before sourcing begins. Use it to align on what 'good' actually looks like. Saves hours of misaligned screening later.",
    "tier": "Daily"
  },
  {
    "id": "1-03",
    "stage": 1,
    "stageTitle": "Intake & Role Passport",
    "type": "verification",
    "title": "Intake Preflight Check",
    "preview": "Audit a role passport for gaps, conflicts, and unrealistic expectations before sourcing begins.",
    "content": "You are a quality auditor for recruiting operations. Review the following Role Passport and identify:\n\n1. MISSING INFORMATION \u2014 What critical fields are empty or vague?\n2. INTERNAL CONFLICTS \u2014 Do any requirements contradict each other? (e.g., junior salary + senior expectations)\n3. LOCATION REALITY \u2014 Is the location requirement realistic for the talent market?\n4. COMPENSATION REALITY \u2014 Is the range competitive for what's being asked?\n5. TIMELINE REALITY \u2014 Is the expected fill time realistic given the requirements?\n6. HIDDEN ASSUMPTIONS \u2014 What is being assumed but not stated?\n\nFor each issue found, provide:\n- The specific problem\n- Why it matters (impact on recruiting)\n- A suggested question to ask the hiring manager\n\nRole Passport:\n[PASTE ROLE PASSPORT HERE]",
    "usageNotes": "Run this before you start sourcing. Every issue caught here saves days of wasted effort downstream. Share the findings with the HM directly.",
    "tier": "Reference"
  },
  {
    "id": "2-01",
    "stage": 2,
    "stageTitle": "JD & Attraction",
    "type": "intake",
    "title": "JD Analyzer",
    "preview": "Analyze an existing job description for vague language, missing information, and candidate deterrents.",
    "content": "Analyze the following job description from a candidate's perspective. Identify:\n\n1. VAGUE PHRASES \u2014 List every phrase that doesn't describe observable behavior (e.g., 'self-starter', 'fast-paced', 'team player'). For each, suggest a concrete replacement.\n2. MISSING INFORMATION \u2014 What would a qualified candidate need to know that isn't here? (comp range, team size, reporting structure, tech stack, day-to-day reality)\n3. CANDIDATE DETERRENTS \u2014 What in this JD would cause a strong candidate to skip it?\n4. UNREALISTIC COMBINATIONS \u2014 Requirements that are rarely found together in one person\n5. READABILITY \u2014 Is it too long? Too corporate? Too generic?\n\nRate the JD overall: Strong / Needs Work / Complete Rewrite\n\nJob Description:\n[PASTE JD HERE]",
    "usageNotes": "Use before posting any JD. Share the analysis with the HM to start a conversation about what really matters vs. what's copy-paste boilerplate.",
    "tier": "Starter"
  },
  {
    "id": "2-02",
    "stage": 2,
    "stageTitle": "JD & Attraction",
    "type": "execution",
    "title": "Candidate-First JD Writer",
    "preview": "Rewrite a job description focused on outcomes, reality, and what the candidate actually cares about.",
    "content": "Rewrite the following job description in a candidate-first format. The output should answer what a strong candidate actually wants to know:\n\n1. WHAT YOU'LL DO (day-to-day reality, not corporate fluff)\n2. WHAT SUCCESS LOOKS LIKE (measurable outcomes in first 6-12 months)\n3. WHAT YOU NEED (only true must-haves, with evidence expectations)\n4. WHAT'S IN IT FOR YOU (real value proposition, not generic benefits)\n5. WHAT'S HARD ABOUT THIS ROLE (honest \u2014 builds credibility)\n\nRules:\n- No jargon or cliches\n- Every requirement must describe observable behavior or verifiable experience\n- Keep it under 500 words\n- Write in direct second person ('You will...')\n\nOriginal JD:\n[PASTE ORIGINAL JD HERE]",
    "usageNotes": "Use this rewrite as the external posting. Keep the original as the internal hiring brief. The gap between the two will reveal alignment issues.",
    "tier": "Daily"
  },
  {
    "id": "2-03",
    "stage": 2,
    "stageTitle": "JD & Attraction",
    "type": "verification",
    "title": "JD Truth Version",
    "preview": "Generate an internal 'truth version' of what a role really involves day-to-day.",
    "content": "Based on the following job description and any additional context, create the 'truth version' \u2014 an internal document that describes what this role ACTUALLY involves.\n\nInclude:\n1. REAL DAY-TO-DAY \u2014 What will this person actually spend their time on? (Be specific: % of time per activity)\n2. REAL CHALLENGES \u2014 What frustrations or obstacles will they face?\n3. REAL TEAM DYNAMICS \u2014 Who do they work with? What's the team culture really like?\n4. REAL GROWTH PATH \u2014 Where does this role actually lead?\n5. WHY THE LAST PERSON LEFT \u2014 If known, or what commonly causes turnover in this type of role\n6. THE UNWRITTEN REQUIREMENTS \u2014 What isn't in the JD but matters for success?\n\nThis document is for internal recruiting use only. Be honest.\n\nJob Description + Context:\n[PASTE JD AND ANY ADDITIONAL NOTES]",
    "usageNotes": "This stays internal. Use it to prep for candidate conversations, screen calls, and to set honest expectations. Honesty early prevents declines later.",
    "tier": "Reference"
  },
  {
    "id": "3-01",
    "stage": 3,
    "stageTitle": "Market & Competitor Reality",
    "type": "intake",
    "title": "Market Intelligence Brief",
    "preview": "Generate a talent market analysis with supply/demand dynamics, competitor landscape, and realistic timelines.",
    "content": "Create a talent market intelligence brief for the following role. I need a reality-based assessment, not optimism.\n\nAnalyze:\n1. TALENT SUPPLY \u2014 How many people with these qualifications realistically exist in this market? Is this a scarce or available profile?\n2. TITLE MAPPING \u2014 What alternative titles do these people use? What adjacent roles could transfer?\n3. COMPETITOR LANDSCAPE \u2014 Which companies are hiring for similar roles? Who are we competing against for this talent?\n4. COMPENSATION REALITY \u2014 What is the realistic market range? How does our range compare?\n5. LOCATION DYNAMICS \u2014 Is remote available from competitors? Are we at a location disadvantage?\n6. RISK ASSESSMENT \u2014 Rate this search: Easy / Moderate / Difficult / Unicorn Hunt. Explain why.\n7. TIMELINE EXPECTATION \u2014 Given the above, what's a realistic time to fill?\n\nSeparate FACTS from ASSUMPTIONS. Mark each data point accordingly.\n\nRole Details:\n[PASTE ROLE PASSPORT OR REQUIREMENTS]",
    "usageNotes": "Present this to the HM before sourcing begins. It sets realistic expectations and positions you as a market advisor, not just a req-filler.",
    "tier": "Daily"
  },
  {
    "id": "3-02",
    "stage": 3,
    "stageTitle": "Market & Competitor Reality",
    "type": "execution",
    "title": "Sourcing Strategy Builder",
    "preview": "Create a multi-lane sourcing strategy with target companies, adjacent industries, and search approaches.",
    "content": "Based on the role requirements and market context below, create a comprehensive sourcing strategy.\n\nBuild 4 SOURCING LANES:\n\n1. PRIMARY LANE \u2014 Direct competitors and obvious companies\n   - List 10 target companies\n   - Expected yield: High match, harder to attract\n\n2. ADJACENT INDUSTRY LANE \u2014 Companies with transferable talent\n   - List 5-8 industries/companies\n   - Why talent from here could work\n\n3. EMERGING TALENT LANE \u2014 Up-and-comers who may be ready to step up\n   - Where to find them\n   - What signals to look for\n\n4. PASSIVE CHANNEL LANE \u2014 Communities, events, content where these people engage\n   - Specific groups, forums, publications\n   - Engagement approach\n\nFor each lane, specify:\n- MUST-HAVE EVIDENCE \u2014 What proof you need to see\n- RED FLAGS \u2014 What to watch out for\n- OUTREACH ANGLE \u2014 Why they'd be interested\n\nRole Requirements:\n[PASTE ROLE PASSPORT]\n\nMarket Context:\n[PASTE ANY MARKET NOTES]",
    "usageNotes": "This becomes your sourcing plan one-pager. Review it with the team during Monday Signal Kickoff. Update it weekly based on what's working.",
    "tier": "Daily"
  },
  {
    "id": "3-03",
    "stage": 3,
    "stageTitle": "Market & Competitor Reality",
    "type": "verification",
    "title": "Risk Memo Generator",
    "preview": "Create a structured risk memo explaining why a role will be easy or hard to fill.",
    "content": "Generate a RISK MEMO for the following role. This document goes to the hiring manager to set expectations.\n\nStructure:\n\nROLE: [Title]\nRISK RATING: [Green = straightforward / Amber = challenging / Red = very difficult]\n\nKEY RISKS:\n1. [Risk] \u2014 [Why it matters] \u2014 [What would mitigate it]\n2. [Risk] \u2014 [Why it matters] \u2014 [What would mitigate it]\n3. [Risk] \u2014 [Why it matters] \u2014 [What would mitigate it]\n\nWHAT WE RECOMMEND:\n- [Specific actions to improve odds]\n- [Trade-offs the HM should consider]\n\nWHAT WE NEED FROM YOU (HM):\n- [Specific decisions or flexibility needed]\n\nBe direct. Do not sugarcoat. The goal is informed decision-making, not comfort.\n\nRole Details + Market Context:\n[PASTE INFORMATION]",
    "usageNotes": "Send this within 48 hours of intake. It positions you as a strategic partner and prevents the 'why is this taking so long?' conversation later.",
    "tier": "Reference"
  },
  {
    "id": "4-01",
    "stage": 4,
    "stageTitle": "Sourcing Blueprint",
    "type": "intake",
    "title": "Persona Card Builder",
    "preview": "Build a detailed target persona card with signals, motivators, and evidence markers for ideal candidates.",
    "content": "Create a TARGET PERSONA CARD for this role. This is the profile of the ideal candidate \u2014 not a job description, but a person description.\n\nBuild:\n\n1. PROFILE SNAPSHOT\n   - Current likely title(s)\n   - Current likely company type/size\n   - Years of relevant experience range\n   - Education (if truly relevant, otherwise mark as 'not a differentiator')\n\n2. CAREER SIGNALS\n   - What their LinkedIn profile looks like\n   - Keywords that appear in their experience\n   - Projects or achievements they'd mention\n   - Certifications or skills that matter (vs. noise)\n\n3. MOTIVATORS (why they'd move)\n   - Career growth angle\n   - Technical/craft challenge angle\n   - Mission/impact angle\n   - What frustrates them in their current role\n\n4. EVIDENCE MARKERS\n   - What you'd see in their background that proves capability\n   - What's verifiable vs. what needs probing\n\n5. ANTI-PATTERNS (who looks right but isn't)\n   - Common false positives\n   - What to watch for\n\nRole Requirements:\n[PASTE ROLE PASSPORT]",
    "usageNotes": "Share this with the full sourcing team. It ensures everyone is looking for the same person, not their own interpretation of the role.",
    "tier": "Starter"
  },
  {
    "id": "4-02",
    "stage": 4,
    "stageTitle": "Sourcing Blueprint",
    "type": "execution",
    "title": "Boolean String Generator",
    "preview": "Generate multi-variant Boolean search strings from strict to broad, with platform-specific syntax.",
    "content": "Generate Boolean search strings for the following role. Create 3 variants:\n\n1. STRICT \u2014 High precision, low recall. Only strong matches.\n2. BALANCED \u2014 Good mix of precision and reach. Best for most searches.\n3. BROAD \u2014 Cast a wide net. Higher volume, more filtering needed.\n\nFor each variant, provide:\n- LinkedIn Recruiter syntax version\n- Google X-ray search version\n- Key assumptions and what to adjust\n\nAlso provide:\n- ALTERNATIVE TITLE SEARCHES \u2014 Different names for the same role\n- ADJACENT SKILL SEARCHES \u2014 Related skills that indicate transferability\n- COMPANY-TARGETED SEARCHES \u2014 Strings focused on specific target companies\n\nRole:\n[PASTE ROLE TITLE AND KEY REQUIREMENTS]\n\nTarget Companies (if any):\n[LIST TARGET COMPANIES]",
    "usageNotes": "Start with STRICT. If pipeline is too thin after 2 days, move to BALANCED. BROAD is your last resort. Track which variant produces the best screen-to-interview conversion.",
    "tier": "Daily"
  },
  {
    "id": "4-03",
    "stage": 4,
    "stageTitle": "Sourcing Blueprint",
    "type": "verification",
    "title": "Profile Scoring Rubric",
    "preview": "Create a standardized scoring rubric to evaluate sourced profiles consistently across the team.",
    "content": "Create a PROFILE SCORING RUBRIC for the following role. This will be used by the entire sourcing team to evaluate profiles consistently.\n\nFor each must-have requirement, create a scoring criteria:\n\nFORMAT:\nRequirement: [from Role Passport]\n- STRONG (3 pts): [What evidence looks like]\n- ADEQUATE (2 pts): [What evidence looks like]\n- WEAK (1 pt): [What evidence looks like]\n- ABSENT (0 pts): [How to identify]\n\nAlso include:\n- MINIMUM SCORE THRESHOLD to proceed to screen\n- AUTOMATIC DISQUALIFIERS (any score of 0 on which requirements = instant no)\n- BONUS SIGNALS (not required but indicate strong fit)\n\nRole Requirements:\n[PASTE ROLE PASSPORT MUST-HAVES]",
    "usageNotes": "Give this to every sourcer working the role. It eliminates the 'I thought they looked good' problem. Review and recalibrate after the first 20 profiles.",
    "tier": "Daily"
  },
  {
    "id": "5-01",
    "stage": 5,
    "stageTitle": "Outreach & Engagement",
    "type": "intake",
    "title": "Outreach Angle Analyzer",
    "preview": "Identify the 3 strongest outreach angles for a specific persona based on motivators and market context.",
    "content": "Based on the persona card and role details below, identify the 3 strongest outreach angles. For each angle, explain:\n\n1. THE HOOK \u2014 What's the core appeal? (1 sentence)\n2. WHY IT WORKS \u2014 What motivator does it tap into?\n3. WHO IT WORKS FOR \u2014 Which segment of the target persona responds to this?\n4. RISK \u2014 When does this angle backfire or feel tone-deaf?\n\nThe 3 angles should be meaningfully different:\n- ANGLE A: Mission / Impact / Purpose\n- ANGLE B: Craft / Mastery / Technical Challenge  \n- ANGLE C: Career Trajectory / Growth / Opportunity\n\nAlso flag: What angle should we AVOID for this specific persona and why?\n\nPersona Card:\n[PASTE PERSONA CARD]\n\nRole Details:\n[PASTE KEY ROLE INFO]",
    "usageNotes": "Pick the angle most relevant to each specific candidate. Don't blast the same message to everyone. Tag each outreach with the angle code (A/B/C) so you can track reply rates.",
    "tier": "Daily"
  },
  {
    "id": "5-02",
    "stage": 5,
    "stageTitle": "Outreach & Engagement",
    "type": "execution",
    "title": "Outreach Message Writer",
    "preview": "Generate personalized outreach messages in 3 angles with follow-up sequences.",
    "content": "Write outreach messages for the following candidate and role. Generate 3 versions \u2014 one per angle.\n\nFor each angle, write:\n\n1. INITIAL MESSAGE (under 100 words)\n   - Personal hook (specific to this candidate's background)\n   - The angle\n   - One clear ask (not 'let me know if interested' \u2014 specific next step)\n\n2. FOLLOW-UP 1 (sent 4 days later, under 80 words)\n   - Adds one new piece of value (not 'just bumping this')\n   - Different framing of the opportunity\n\n3. FOLLOW-UP 2 (sent 7 days later, under 60 words)\n   - Final touch, respectful close\n   - Leave door open without being pushy\n\nRULES:\n- No buzzwords, no recruiter cliches\n- No 'I came across your profile'\n- Short sentences. Direct language.\n- Sound like a person, not a template\n\nCandidate Background:\n[PASTE CANDIDATE INFO]\n\nRole + Angle Details:\n[PASTE ROLE INFO AND CHOSEN ANGLES]",
    "usageNotes": "Tag every message sent with the angle code (A/B/C). Track reply rates per angle in your weekly Telemetry. After 2 weeks, double down on the winning angle.",
    "tier": "Starter"
  },
  {
    "id": "5-03",
    "stage": 5,
    "stageTitle": "Outreach & Engagement",
    "type": "verification",
    "title": "Outreach Quality Check",
    "preview": "Audit an outreach message for recruiter cliches, weak CTAs, and misalignment with candidate motivators.",
    "content": "Review the following outreach message and provide a brutally honest assessment.\n\nCheck for:\n1. RECRUITER CLICHES \u2014 Flag any generic phrases ('exciting opportunity', 'I came across your profile', 'perfect fit')\n2. CTA STRENGTH \u2014 Is the ask clear and specific? Or vague and easy to ignore?\n3. PERSONALIZATION \u2014 Is this message clearly written for THIS person? Or could it go to anyone?\n4. LENGTH \u2014 Is it respectfully short? (Under 100 words for initial outreach)\n5. VALUE \u2014 Does it give the candidate a reason to respond? What's in it for them?\n6. ANGLE CLARITY \u2014 Which motivator is this message targeting? Is it clear?\n7. TONE \u2014 Does it sound like a person or a template?\n\nRate: Strong / Needs Work / Rewrite\n\nProvide a rewritten version if rating is 'Needs Work' or 'Rewrite'.\n\nOutreach Message:\n[PASTE MESSAGE]",
    "usageNotes": "Run every outreach template through this before using it. Use it in Friday Proof + Learn sessions to improve as a team.",
    "tier": "Reference"
  },
  {
    "id": "6-01",
    "stage": 6,
    "stageTitle": "Recruiter Screen",
    "type": "intake",
    "title": "Screen Script Generator",
    "preview": "Generate a structured screening script with evidence-based questions aligned to role must-haves.",
    "content": "Generate a structured SCREENING SCRIPT for the following role. This is a 15-20 minute call, not an interview. Focus on qualifying, not selling.\n\nStructure:\n\n1. OPENING (1 minute)\n   - Quick context on the role and the call purpose\n   - Set expectation: 'This is a quick conversation to explore fit on both sides'\n\n2. EVIDENCE QUESTIONS (3 questions, 8-10 minutes)\n   For each must-have requirement, generate one targeted question:\n   - The question (behavioral: 'Tell me about a time when...')\n   - What a strong answer sounds like\n   - What a weak answer sounds like\n   - Follow-up probe if the answer is vague\n\n3. CONSTRAINT CHECK (2 minutes)\n   - Location/availability question\n   - Compensation expectations question\n   - Notice period question\n\n4. MOTIVATION CHECK (2 minutes)\n   - 'Why are you considering a move right now?'\n   - 'What would make this the right next step for you?'\n\n5. CLOSE (1 minute)\n   - Clear next step\n   - Timeline\n\nRole Requirements:\n[PASTE ROLE PASSPORT]",
    "usageNotes": "Use this script for every screen on this role. Consistency lets you compare candidates fairly. Adapt the evidence questions if the role passport updates.",
    "tier": "Starter"
  },
  {
    "id": "6-02",
    "stage": 6,
    "stageTitle": "Recruiter Screen",
    "type": "execution",
    "title": "Screen Notes Structurer",
    "preview": "Convert raw screen notes into structured evidence, separating facts from interpretation.",
    "content": "Structure the following raw screening notes into a formatted assessment. Separate EVIDENCE from INTERPRETATION.\n\nFormat:\n\nCANDIDATE: [Name]\nROLE: [Title]\nSCREEN DATE: [Date]\n\nEVIDENCE SUMMARY:\nFor each area discussed:\n- What the candidate SAID (direct evidence)\n- What this SUGGESTS (your interpretation)\n- Confidence level: High / Medium / Low\n\nCONSTRAINT CHECK:\n- Location: [Confirmed / Risk / Blocker]\n- Compensation: [Aligned / Risk / Blocker]\n- Availability: [Confirmed / Risk / Blocker]\n\nMOTIVATION:\n- Primary driver: [what]\n- Evidence this is genuine: [how you know]\n- Risk: [what could change their mind]\n\nOVERALL ASSESSMENT:\n- Recommendation: Advance / Hold / Pass\n- Confidence: High / Medium / Low\n- Missing evidence: [what you still don't know]\n\nRaw Screen Notes:\n[PASTE YOUR NOTES]",
    "usageNotes": "Do this immediately after every screen. The structured output becomes your Truth Check record and feeds directly into the Confidence Pack if the candidate advances.",
    "tier": "Daily"
  },
  {
    "id": "6-03",
    "stage": 6,
    "stageTitle": "Recruiter Screen",
    "type": "verification",
    "title": "Screen Decision Validator",
    "preview": "Challenge a screen recommendation by testing for bias, missing evidence, and false confidence.",
    "content": "Review the following screening assessment and challenge the recommendation. Act as a quality control checkpoint.\n\nCheck:\n1. EVIDENCE STRENGTH \u2014 Is the recommendation supported by specific evidence, or based on impression?\n2. MISSING DATA \u2014 What critical questions were not asked or answered?\n3. BIAS CHECK \u2014 Are there signs of:\n   - Confirmation bias (interpreting everything as positive)?\n   - Halo effect (one strong point overshadowing gaps)?\n   - Similarity bias (the candidate 'feels like a fit' without evidence)?\n4. RISK BLINDSPOTS \u2014 What could go wrong that isn't flagged?\n5. DECISION CONFIDENCE \u2014 Given the evidence available, is the recommendation justified?\n\nOutput:\n- Agree / Disagree / Need More Info\n- Key concerns (if any)\n- Suggested next steps\n\nScreening Assessment:\n[PASTE STRUCTURED SCREEN NOTES]",
    "usageNotes": "Run this on any candidate you're advancing. It takes 2 minutes and catches issues before they become HM rejections.",
    "tier": "Reference"
  },
  {
    "id": "7-01",
    "stage": 7,
    "stageTitle": "Submission & HM Prep",
    "type": "intake",
    "title": "Submission Requirements Check",
    "preview": "Verify all required evidence is present before building a submission package.",
    "content": "Before building a candidate submission, verify all requirements are met.\n\nChecklist \u2014 for each item, confirm Present / Missing / Partial:\n\n1. [ ] Must-have #1 evidence captured with specific example\n2. [ ] Must-have #2 evidence captured with specific example\n3. [ ] Must-have #3 evidence captured with specific example\n4. [ ] Location confirmed and realistic\n5. [ ] Compensation expectations within approved range\n6. [ ] Availability/notice period documented\n7. [ ] Motivation is genuine and verified\n8. [ ] At least one risk identified with mitigation plan\n9. [ ] Screen notes structured (not raw)\n10. [ ] Candidate has confirmed interest in THIS specific role\n\nFor any MISSING or PARTIAL item:\n- What's missing\n- Can we proceed without it? (Yes/No/Risk)\n- How to get it\n\nCandidate Details:\n[PASTE CANDIDATE INFO AND SCREEN NOTES]",
    "usageNotes": "If more than 2 items are missing, do NOT submit. Go back and gather the evidence. A weak submission erodes HM trust.",
    "tier": "Daily"
  },
  {
    "id": "7-02",
    "stage": 7,
    "stageTitle": "Submission & HM Prep",
    "type": "execution",
    "title": "Confidence Pack Writer",
    "preview": "Generate a one-page candidate submission with match evidence, risks, and HM interview recommendations.",
    "content": "Create a CONFIDENCE PACK for the following candidate. This is a one-page submission document that gives the hiring manager everything they need to make a decision.\n\nFormat:\n\nCANDIDATE: [Name]\nCURRENT: [Title @ Company]\nROLE: [Target role]\n\nWHY THIS CANDIDATE (3 match reasons):\n1. [Must-have #1] \u2014 Evidence: [specific example from screen]\n2. [Must-have #2] \u2014 Evidence: [specific example from screen]\n3. [Must-have #3] \u2014 Evidence: [specific example from screen]\n\nRISK TO KNOW:\n- [The primary risk] \u2014 Mitigation: [how to address it]\n\nRECOMMENDED NEXT STEP:\n- [Specific recommendation: interview format, who should interview, what to test]\n\nSUGGESTED INTERVIEW FOCUS:\n- [What the HM should probe that wasn't fully covered in screen]\n\nRules:\n- Every claim must have evidence\n- Be honest about risks \u2014 don't hide them\n- Keep it under 250 words\n\nCandidate Details + Screen Notes:\n[PASTE ALL CANDIDATE INFO]",
    "usageNotes": "This replaces the typical 'here's a CV, let me know what you think' email. Every shortlist member gets a Confidence Pack. It's how you build HM trust.",
    "tier": "Starter"
  },
  {
    "id": "7-03",
    "stage": 7,
    "stageTitle": "Submission & HM Prep",
    "type": "verification",
    "title": "HM Briefing Questions Generator",
    "preview": "Generate targeted interview questions for the hiring manager based on what still needs validation.",
    "content": "Based on the candidate's Confidence Pack and remaining unknowns, generate a briefing for the hiring manager.\n\nProvide:\n\n1. INTERVIEW FOCUS AREAS (top 3)\n   For each:\n   - What to test\n   - Why it matters for this role\n   - A specific question to ask\n   - What a strong answer sounds like\n   - What a concerning answer sounds like\n\n2. DON'T RE-ASK\n   - [Areas already validated in screen \u2014 save time]\n\n3. CANDIDATE'S LIKELY QUESTIONS\n   - What will the candidate ask you?\n   - Suggested answers that are honest and compelling\n\n4. DECISION FRAMEWORK\n   After the interview, the HM should be able to answer:\n   - Can this person do the job? (Evidence)\n   - Will this person do the job here? (Motivation)\n   - Can we close them? (Realistic)\n\nConfidence Pack:\n[PASTE CONFIDENCE PACK]\n\nRemaining Unknowns:\n[LIST WHAT WASN'T FULLY VALIDATED]",
    "usageNotes": "Send this to the HM with the Confidence Pack. It guides their interview so they test what matters, not whatever comes to mind.",
    "tier": "Daily"
  },
  {
    "id": "8-01",
    "stage": 8,
    "stageTitle": "Interview Loop Design",
    "type": "execution",
    "title": "Interview Loop Planner",
    "preview": "Design a structured interview loop assigning specific competencies to each interviewer to eliminate redundancy.",
    "content": "Design a structured INTERVIEW LOOP for the following role. The goal is maximum signal with minimum redundancy.\n\nInputs needed:\n- Number of interviewers: [NUMBER]\n- Competencies to assess: [LIST FROM ROLE PASSPORT]\n\nFor each interviewer, assign:\n\nINTERVIEWER [N]: [Name/Role]\n- OWNS: [1-2 competencies to assess]\n- DO NOT ASK ABOUT: [competencies assigned to others]\n- QUESTIONS: [2-3 specific questions with scoring anchors]\n- FORMAT: [Behavioral / Technical / Case / Presentation]\n- DURATION: [minutes]\n\nLOOP RULES:\n- No competency assessed by more than 2 interviewers\n- Every must-have competency assessed by at least 1 interviewer\n- Total loop time should not exceed [X] hours\n- Include debrief guidelines\n\nRole Requirements:\n[PASTE ROLE PASSPORT]",
    "usageNotes": "Distribute to all interviewers before the interview. Each person knows exactly what to test. The debrief becomes evidence-based, not a vibe session.",
    "tier": "Daily"
  },
  {
    "id": "9-01",
    "stage": 9,
    "stageTitle": "Debrief & Decision",
    "type": "execution",
    "title": "Debrief Summarizer",
    "preview": "Compile interview feedback into an evidence matrix showing agreement, contradictions, and decision factors.",
    "content": "Compile the following interview feedback into a structured DEBRIEF SUMMARY.\n\nCreate:\n\n1. EVIDENCE MATRIX\n   For each competency assessed:\n   | Competency | Interviewer 1 | Interviewer 2 | Consensus |\n   - Rating: Strong / Adequate / Weak\n   - Key evidence cited\n\n2. CONTRADICTIONS\n   - Where interviewers disagreed\n   - What might explain the disagreement\n   - What additional data would resolve it\n\n3. DECISION OPTIONS\n   Option A: HIRE \u2014 Supporting evidence + risks accepted\n   Option B: PASS \u2014 Specific gaps that can't be mitigated\n   Option C: NEED MORE \u2014 What additional step would resolve uncertainty\n\n4. 'WHAT WOULD CHANGE MY MIND?' TRIGGERS\n   - If hiring: What would make you regret this?\n   - If passing: What would change this to a yes?\n\nFlag any 'vibe language' (felt off, seemed great, good culture fit) and translate to observable evidence.\n\nInterview Feedback:\n[PASTE ALL INTERVIEWER NOTES]",
    "usageNotes": "Use this in the debrief meeting. It keeps the conversation evidence-based and produces a defensible decision record.",
    "tier": "Daily"
  },
  {
    "id": "10-01",
    "stage": 10,
    "stageTitle": "Offer & Close",
    "type": "execution",
    "title": "Offer Close Plan Builder",
    "preview": "Create a structured close plan with motivator mapping, objection counters, and timeline milestones.",
    "content": "Build an OFFER CLOSE PLAN for the following candidate.\n\n1. MOTIVATOR MAP\n   - Primary motivator: [what] \u2014 Evidence: [how you know]\n   - Secondary motivator: [what] \u2014 Evidence: [how you know]\n   - What they care LEAST about: [important for negotiation framing]\n\n2. LIKELY OBJECTIONS + COUNTERS\n   For each potential objection:\n   - Objection: [what they might push back on]\n   - Counter: [how to address it]\n   - Proof point: [evidence or data to support the counter]\n\n3. COMPETITIVE RISK\n   - Are they interviewing elsewhere? [Yes/No/Unknown]\n   - Who are we competing against?\n   - Our advantage over alternatives:\n   - Our disadvantage:\n\n4. CLOSE TIMELINE\n   - Day 1: [Action \u2014 who does what]\n   - Day 2-3: [Follow-up action]\n   - Day 5: [Decision deadline]\n   - Escalation trigger: [when to involve leadership]\n\n5. SINGLE CTA\n   - The ONE thing you want the candidate to do after receiving the offer\n\nCandidate Details:\n[PASTE CANDIDATE INFO + INTERVIEW NOTES + OFFER DETAILS]",
    "usageNotes": "Build this before extending the offer, not after. Anticipate objections and have answers ready. The close starts at the first outreach, not at the offer.",
    "tier": "Starter"
  },
  {
    "id": "10-02",
    "stage": 10,
    "stageTitle": "Offer & Close",
    "type": "verification",
    "title": "Decline Analysis",
    "preview": "Analyze an offer decline to extract learning, assign reason codes, and improve future close strategies.",
    "content": "Analyze the following offer decline and extract actionable learning.\n\nStructure:\n\n1. DECLINE REASON CODE (select primary):\n   - COMP: Compensation gap\n   - COUNTER: Accepted counter-offer\n   - COMPETITOR: Chose another company\n   - FIT: Role/culture mismatch perceived\n   - PERSONAL: Personal/family reasons\n   - TIMELINE: Process took too long\n   - UNKNOWN: Candidate ghosted or gave vague reason\n\n2. ROOT CAUSE ANALYSIS\n   - What was the stated reason?\n   - What was the likely real reason?\n   - At what stage did we lose them? (Was the signal there earlier?)\n\n3. WHAT COULD WE HAVE DONE DIFFERENTLY?\n   - In sourcing/outreach?\n   - In screening?\n   - In the interview process?\n   - In the offer/close?\n\n4. REUSABLE LEARNING\n   - What should we change for the next candidate on this role?\n   - What should we change for similar roles in the future?\n\nDecline Details:\n[PASTE ALL RELEVANT INFORMATION]",
    "usageNotes": "Do this for every decline. The learning compounds over time. Share in Friday Proof + Learn and update the Asset Library.",
    "tier": "Reference"
  },
  {
    "id": "11-01",
    "stage": 11,
    "stageTitle": "Preboarding & Compliance",
    "type": "execution",
    "title": "Preboarding Sequence Generator",
    "preview": "Create a structured preboarding communication sequence from offer acceptance to day one.",
    "content": "Create a PREBOARDING COMMUNICATION SEQUENCE for the following hire.\n\nGenerate messages for each milestone:\n\n1. OFFER ACCEPTANCE (Day 0)\n   - Congratulatory message\n   - What happens next (clear timeline)\n   - Key contacts\n\n2. DOCUMENTS & COMPLIANCE (Day 1-3)\n   - What's needed, by when\n   - How to submit\n   - Who to contact if stuck\n\n3. MID-POINT CHECK-IN (Halfway to start)\n   - Warm touchpoint\n   - Any questions?\n   - Excitement builder about the team/role\n\n4. WEEK BEFORE START\n   - Day 1 logistics (where, when, who to ask for)\n   - What to expect in week 1\n   - Informal: team intro or welcome note\n\n5. INTERNAL CHECKLIST (for us)\n   - [ ] Background check initiated\n   - [ ] Equipment ordered\n   - [ ] Access/accounts requested\n   - [ ] Manager briefed on start date\n   - [ ] Onboarding schedule confirmed\n\nRules:\n- Warm but professional tone\n- Each message under 150 words\n- Always include a clear next step\n\nNew Hire Details:\n[PASTE NAME, ROLE, START DATE, RELEVANT DETAILS]",
    "usageNotes": "Set these up as templates that can be personalized per hire. The goal: zero radio silence between offer and start. That's where ghosting happens.",
    "tier": "Daily"
  },
  {
    "id": "12-01",
    "stage": 12,
    "stageTitle": "Postmortem & Improvement",
    "type": "execution",
    "title": "Pipeline Autopsy",
    "preview": "Run a structured postmortem analyzing where candidates dropped, what worked, and what to change.",
    "content": "Run a PIPELINE AUTOPSY for the following role (or set of roles). This is a monthly learning exercise.\n\nAnalyze:\n\n1. FUNNEL ANALYSIS\n   - How many sourced \u2192 screened \u2192 submitted \u2192 interviewed \u2192 offered \u2192 hired?\n   - Where was the biggest drop-off?\n   - Was the drop-off a volume problem or a relevance problem?\n\n2. WHAT WORKED\n   - Which sourcing lane produced the best candidates?\n   - Which outreach angle got the best replies?\n   - What screening questions were most predictive?\n\n3. WHAT DIDN'T WORK\n   - Where did we waste the most time?\n   - What assumption was wrong?\n   - What would we do differently if starting over?\n\n4. TEMPLATE UPDATES NEEDED\n   - Role Passport: [what to change]\n   - Sourcing Blueprint: [what to change]\n   - Screen Script: [what to change]\n   - Outreach Angles: [what to change]\n\n5. THREE LEARNING ENTRIES\n   - Learning 1: [specific, actionable]\n   - Learning 2: [specific, actionable]\n   - Learning 3: [specific, actionable]\n\nRole Data:\n[PASTE PIPELINE NUMBERS AND NOTES]",
    "usageNotes": "Run this monthly for all closed roles. Share findings in the monthly postmortem. Update the Asset Library with improved templates.",
    "tier": "Reference"
  },
  {
    "id": "8-02",
    "stage": 8,
    "stageTitle": "Interview Loop Design",
    "type": "intake",
    "title": "Interview Competency Mapper",
    "preview": "Map role requirements to interviewers and competency areas with evidence expectations for each slot.",
    "content": "You are a senior recruiting operations strategist. I need to design an interview loop that produces maximum signal with zero redundancy. Before building the loop, I need to map competencies to interviewers.\n\nUsing the role requirements below, create an INTERVIEW COMPETENCY MAP:\n\n1. COMPETENCY EXTRACTION\n   From the Role Passport, identify every competency that must be assessed:\n   - Technical competencies (hard skills, domain knowledge, tools)\n   - Behavioral competencies (leadership, collaboration, communication)\n   - Motivational fit (alignment with role, team, company)\n   List each competency with the evidence standard: what does Strong / OK / Weak look like?\n\n2. INTERVIEWER ASSIGNMENT MATRIX\n   For each available interviewer:\n   | Interviewer | Role/Title | Best Suited to Assess | Why |\n   - Assign 1-2 competencies per interviewer based on their expertise\n   - Flag competencies that NO available interviewer can properly assess\n   - Ensure zero overlap: no competency tested by more than 2 people\n\n3. EVIDENCE EXPECTATIONS\n   For each competency-interviewer pairing:\n   - What specific evidence should this interviewer seek?\n   - What question format works best? (behavioral, technical, case, live exercise)\n   - What answer would make you confident? What would concern you?\n\n4. GAP ANALYSIS\n   - Which must-have competencies have NO interviewer assigned?\n   - Which competencies are over-covered (tested by 3+ people)?\n   - What format is missing? (e.g., all behavioral, no technical validation)\n\nRole Requirements:\n[PASTE ROLE PASSPORT]\n\nAvailable Interviewers:\n[LIST NAMES, TITLES, AND AREAS OF EXPERTISE]",
    "usageNotes": "Run this before building the interview loop. It prevents the common trap of interviewers asking whatever comes to mind. Share the output with the Interview Loop Planner prompt to generate the final loop design.",
    "tier": "Daily"
  },
  {
    "id": "8-03",
    "stage": 8,
    "stageTitle": "Interview Loop Design",
    "type": "verification",
    "title": "Interview Loop Quality Audit",
    "preview": "Audit a proposed interview loop for coverage gaps, redundancy, bias risk, and missing scorecards.",
    "content": "You are an interview process quality auditor. Review the following interview loop design and identify issues before candidates enter the process.\n\nAudit for:\n\n1. COVERAGE GAPS\n   - Which must-have competencies from the Role Passport are NOT being assessed?\n   - Which competencies are only assessed by one interviewer with no backup signal?\n   - Is motivation and fit being assessed, or only technical skill?\n\n2. REDUNDANCY\n   - Which questions or competencies are being tested by multiple interviewers?\n   - Where will interviewers ask essentially the same thing in different words?\n   - What time is being wasted on duplicate coverage?\n\n3. SCORECARD QUALITY\n   For each interviewer's scorecard, check:\n   - Are scoring anchors specific? (Not just 'good' / 'bad' but observable behaviors)\n   - Is there a clear definition of Strong / OK / Weak for each competency?\n   - Can two different interviewers read the same scorecard and score consistently?\n\n4. BIAS RISK\n   - Are any questions likely to produce biased signals? (e.g., cultural fit without definition, 'would you grab a beer with them')\n   - Is the loop diverse in interviewer perspectives?\n   - Are structured scorecards in place to prevent halo effects?\n   - Could any question inadvertently screen for protected characteristics?\n\n5. CANDIDATE EXPERIENCE\n   - Is the total loop length reasonable for the level? (IC: 3-4 hours max, leadership: 4-5 hours max)\n   - Are there unnecessarily repetitive stages from the candidate's perspective?\n   - Does the order make sense? (Don't lead with the hardest technical round if the role is borderline)\n\nFor each issue found, provide:\n- ISSUE: [What's wrong]\n- IMPACT: [What happens if you don't fix it]\n- FIX: [Specific recommendation]\n\nRate the overall loop: Ready / Needs Fixes / Redesign\n\nInterview Loop Design:\n[PASTE THE INTERVIEW LOOP PLAN]\n\nRole Passport:\n[PASTE THE ROLE PASSPORT FOR REFERENCE]",
    "usageNotes": "Run this on every interview loop before the first candidate enters. A broken loop wastes everyone's time and produces unreliable signal. Fix issues now, not after three interviews.",
    "tier": "Reference"
  },
  {
    "id": "9-02",
    "stage": 9,
    "stageTitle": "Debrief & Decision",
    "type": "intake",
    "title": "Debrief Prep Builder",
    "preview": "Prepare a structured debrief agenda from interview feedback, surfacing contradictions and evidence gaps before the meeting.",
    "content": "You are a hiring decision facilitator. Using the interview feedback below, prepare a DEBRIEF PREP DOCUMENT so the team walks into the meeting with clarity, not chaos.\n\nBuild:\n\n1. PRE-READ SUMMARY (send to all interviewers 30 minutes before debrief)\n   - Candidate name and role\n   - Number of interviews completed\n   - Quick signal overview: How many Strong / OK / Weak / Risk ratings across all competencies?\n\n2. CONSENSUS MAP\n   For each competency assessed:\n   | Competency | Interviewer A | Interviewer B | Interviewer C | Agreement? |\n   - Flag where all interviewers agree (no discussion needed)\n   - Flag where interviewers disagree (must discuss)\n   - Flag where evidence is thin or missing (must address)\n\n3. CONTRADICTIONS TO RESOLVE\n   For each disagreement:\n   - What Interviewer A observed: [evidence]\n   - What Interviewer B observed: [evidence]\n   - Possible explanations: [candidate showed different sides, question framing, interviewer bias, etc.]\n   - Suggested resolution approach: [re-probe, accept the variance, weight one signal higher]\n\n4. EVIDENCE GAPS\n   - Which must-haves from the Role Passport still lack strong evidence?\n   - What would it take to close the gap? (Additional reference check, follow-up call, work sample)\n   - Can we make a confident decision without this evidence, or is it a blocker?\n\n5. DEBRIEF AGENDA (suggested 30-minute structure)\n   - Minutes 0-5: Each interviewer states their recommendation and top evidence point (no debate yet)\n   - Minutes 5-15: Discuss contradictions from the consensus map\n   - Minutes 15-20: Address evidence gaps and decide if they are blocking\n   - Minutes 20-25: Decision discussion using the evidence matrix\n   - Minutes 25-30: Document decision, rationale, and next steps\n\n6. DECISION FRAMEWORK REMINDER\n   The team should answer three questions:\n   - Can this person do the job? (Skill evidence)\n   - Will this person do the job here? (Motivation and fit evidence)\n   - Can we close them? (Constraint and timeline reality)\n\nInterview Feedback:\n[PASTE ALL INTERVIEWER SCORECARDS AND NOTES]",
    "usageNotes": "Send the pre-read summary to all interviewers 30 minutes before the debrief. Walk in with an agenda, not an open floor. This turns a 60-minute argument into a 30-minute decision.",
    "tier": "Daily"
  },
  {
    "id": "9-03",
    "stage": 9,
    "stageTitle": "Debrief & Decision",
    "type": "verification",
    "title": "Hiring Decision Challenger",
    "preview": "Challenge a hiring decision for bias, halo effects, anchoring, and missing evidence before it becomes final.",
    "content": "You are a hiring decision quality reviewer. Your job is to stress-test a hiring decision \u2014 whether it is a YES, NO, or MAYBE \u2014 before it becomes final. You are not trying to reverse the decision. You are trying to make sure it is defensible.\n\nReview the decision and challenge it on:\n\n1. EVIDENCE STRENGTH\n   - Is every 'yes' reason backed by a specific, observable data point from the interviews?\n   - Are any reasons based on impression, gut feeling, or pattern-matching? Flag them.\n   - Would this evidence hold up if someone asked 'how do you know that?' for each claim?\n\n2. BIAS CHECK\n   Scan for these common biases:\n   - HALO EFFECT: One strong data point overshadowing gaps elsewhere\n   - SIMILARITY BIAS: 'Culture fit' that really means 'reminds me of myself'\n   - ANCHORING: Over-weighting the first or last interviewer's opinion\n   - CONFIRMATION BIAS: Interpreting ambiguous evidence as supporting the existing lean\n   - CONTRAST EFFECT: Comparing this candidate to the previous one rather than to the role requirements\n   For each bias detected, flag the specific evidence and suggest how to reframe.\n\n3. WHAT'S MISSING\n   - Which Role Passport must-haves have no strong evidence from any interviewer?\n   - Are you proceeding with unknowns, and are those unknowns acceptable?\n   - What would a dissenting interviewer say if they challenged this decision?\n\n4. REVERSE TEST\n   - If the decision is HIRE: Write the strongest case for passing. What would change your mind?\n   - If the decision is PASS: Write the strongest case for hiring. What evidence would tip the balance?\n   - If the decision is NEED MORE: What specific evidence would make this a clear yes or no?\n\n5. DECISION CONFIDENCE SCORE\n   Rate: High / Medium / Low\n   - High: Strong evidence on all must-haves, no unresolved contradictions, team aligned\n   - Medium: Some gaps but manageable risks, minor disagreements resolved\n   - Low: Significant evidence gaps, unresolved contradictions, team split\n\n   If confidence is Medium or Low, recommend: proceed with risk noted, gather more data, or do not proceed.\n\nHiring Decision + Evidence:\n[PASTE DEBRIEF SUMMARY AND TEAM DECISION]",
    "usageNotes": "Run this before communicating any hiring decision to the candidate. It takes 5 minutes and catches the biases that cost you regret hires. Share the output with the hiring manager as part of the decision record.",
    "tier": "Reference"
  },
  {
    "id": "10-03",
    "stage": 10,
    "stageTitle": "Offer & Close",
    "type": "intake",
    "title": "Candidate Motivator Map",
    "preview": "Build a structured motivator profile from all candidate touchpoints to inform offer design and close strategy.",
    "content": "You are a senior recruiting strategist specializing in offer negotiation and close. Using all available candidate data, build a CANDIDATE MOTIVATOR MAP that will drive the offer strategy.\n\nExtract from all touchpoints (screen notes, interview feedback, informal conversations):\n\n1. PRIMARY MOTIVATORS (ranked by importance to the candidate)\n   For each motivator:\n   - What it is (compensation, growth, mission, craft, flexibility, team, stability, etc.)\n   - Evidence: When and how did the candidate express this? (Direct quote if available)\n   - Strength: Is this a dealmaker, a preference, or nice-to-have?\n\n2. DEALBREAKERS (what would cause a decline)\n   - Non-negotiable constraints the candidate has stated\n   - Evidence: Exact quotes or observations\n   - Can we meet this? Yes / No / Partially \u2014 with specifics\n\n3. OFFER MATCH ANALYSIS\n   | Motivator | Candidate Wants | What We Can Offer | Gap? | Mitigation |\n   - Identify where the offer fully meets expectations\n   - Identify where there is a gap\n   - For each gap, propose a mitigation or reframing\n\n4. COMPETITIVE LANDSCAPE\n   - Is the candidate actively interviewing elsewhere? With whom?\n   - What do competitors likely offer that we don't?\n   - What do we offer that competitors can't match?\n   - Evidence: How do you know? (Candidate stated, market intel, assumption)\n\n5. COUNTER-OFFER RISK\n   - Is the candidate likely to receive a counter from current employer?\n   - What would the counter likely include?\n   - How to pre-empt: What to say before the counter arrives\n\n6. CLOSE APPROACH RECOMMENDATION\n   - Lead with: [The motivator that our offer best addresses]\n   - Acknowledge: [The gap the candidate will notice]\n   - Pre-empt: [The objection they will raise]\n   - Timeline: [When to extend, when to follow up, when to close]\n\nCandidate Data:\n[PASTE ALL SCREEN NOTES, INTERVIEW FEEDBACK, AND INFORMAL OBSERVATIONS]",
    "usageNotes": "Build this before designing the offer package. The offer should be structured around what the candidate actually cares about, not what you assume they want. Share the match analysis with the HM so the offer is designed to close, not just to comply.",
    "tier": "Reference"
  },
  {
    "id": "11-02",
    "stage": 11,
    "stageTitle": "Preboarding & Compliance",
    "type": "intake",
    "title": "Compliance Checklist Generator",
    "preview": "Generate a complete preboarding checklist with deadlines, owners, and escalation triggers for any role and location.",
    "content": "You are a recruiting operations specialist. Generate a comprehensive PREBOARDING COMPLIANCE CHECKLIST for the following hire. This checklist must ensure nothing falls through the cracks between offer acceptance and day one.\n\nBuild the checklist with:\n\n1. CANDIDATE-FACING ITEMS\n   For each item:\n   | Item | Deadline | Status | Owner | Escalation Trigger |\n   Include:\n   - Employment contract / offer letter signed\n   - Right-to-work documentation\n   - Background check consent and completion\n   - Reference checks (if applicable)\n   - Pre-employment medical (if required)\n   - Confidentiality / IP agreements\n   - Benefits enrollment paperwork\n   - Banking / payroll details\n   - Emergency contact information\n   - Any role-specific certifications or clearances\n\n2. INTERNAL ITEMS\n   For each item:\n   | Item | Deadline | Status | Owner | Escalation Trigger |\n   Include:\n   - IT equipment order and provisioning\n   - System access and account creation\n   - Badge / building access setup\n   - Desk / workspace assignment\n   - Manager onboarding plan confirmed\n   - Team introduction scheduled\n   - Day 1 agenda created and shared\n   - Buddy or onboarding partner assigned\n   - Payroll setup confirmed with HR/finance\n\n3. ESCALATION RULES\n   - If any candidate-facing item is overdue by 3+ business days: escalate to [recruiter + hiring manager]\n   - If any internal item is overdue by 5+ business days: escalate to [recruiting ops + HR]\n   - If background check flags an issue: immediate escalation to [HR compliance]\n   - If candidate goes silent for 5+ days: recruiter calls directly, then escalates\n\n4. COMMUNICATION SCHEDULE\n   - Day 0: Welcome message with full timeline\n   - Day 3: Document submission reminder (if not received)\n   - Midpoint: Warm check-in with team preview\n   - Week before: Day 1 logistics and expectations\n   - Day -1: Final confirmation and welcome\n\nAdapt the checklist based on:\n- Country/entity: [SPECIFY \u2014 compliance requirements vary by jurisdiction]\n- Role level: [Junior / Mid / Senior / Leadership \u2014 some steps differ]\n- Start timeline: [Days between offer and start \u2014 compress or expand accordingly]\n\nNew Hire Details:\n[PASTE NAME, ROLE, LOCATION, ENTITY, START DATE, ANY SPECIAL REQUIREMENTS]",
    "usageNotes": "Generate this the day the offer is accepted. Assign owners immediately. Review the checklist in Wednesday Pipeline Truth Check. A missed compliance item can delay a start date by weeks.",
    "tier": "Daily"
  },
  {
    "id": "11-03",
    "stage": 11,
    "stageTitle": "Preboarding & Compliance",
    "type": "verification",
    "title": "Preboarding Risk Scanner",
    "preview": "Review current preboarding status and flag at-risk items, communication gaps, and start date threats.",
    "content": "You are a preboarding risk analyst. Review the current status of preboarding for the following hire and identify everything that could delay or derail the start date.\n\nScan for:\n\n1. OVERDUE ITEMS\n   For each item that is past its deadline:\n   - What is overdue and by how many days?\n   - Who is the owner and have they been reminded?\n   - What is the impact if this remains unresolved? (Blocks start / delays onboarding / minor)\n   - Recommended action: [Specific next step with timeline]\n\n2. AT-RISK ITEMS\n   Items not yet overdue but showing warning signs:\n   - Background check taking longer than expected\n   - Candidate slow to respond to document requests\n   - IT equipment not yet ordered with start date approaching\n   - Manager has not confirmed onboarding plan\n   Rate each: Low Risk / Medium Risk / High Risk\n\n3. COMMUNICATION GAPS\n   - When was the last candidate touchpoint? If more than 5 business days, flag immediately.\n   - Has the candidate received a complete timeline of what's expected?\n   - Has the candidate been introduced to their team or manager since accepting?\n   - Is there any sign of reduced engagement? (Slow replies, vague answers, postponed conversations)\n\n4. COUNTER-OFFER / GHOSTING RISK\n   Based on the candidate's behavior since acceptance:\n   - Engagement level: Strong / Neutral / Concerning\n   - Warning signs: [List any behavioral signals]\n   - Mitigation: [What to do right now to reduce flight risk]\n\n5. START DATE CONFIDENCE\n   Rate: Green (on track) / Amber (at risk) / Red (likely delay)\n   - If Amber or Red: What needs to happen this week to get back to Green?\n   - Estimated revised start date if issues persist: [Date]\n\nCurrent Preboarding Status:\n[PASTE THE COMPLIANCE CHECKLIST WITH CURRENT STATUS FOR EACH ITEM]\n\nLast Communication with Candidate:\n[PASTE DATE AND CONTENT OF LAST TOUCHPOINT]",
    "usageNotes": "Run this weekly for every hire in preboarding. Bring the output to Wednesday Pipeline Truth Check. The goal is zero surprises on start day. One red flag caught early saves weeks of recovery.",
    "tier": "Reference"
  },
  {
    "id": "12-02",
    "stage": 12,
    "stageTitle": "Postmortem & Improvement",
    "type": "intake",
    "title": "Learning Capture Template",
    "preview": "Structure post-fill reflections into specific, reusable learning entries that improve future recruiting cycles.",
    "content": "You are a recruiting process improvement specialist. For the following completed search (filled or unfilled), capture structured learning entries that will improve future performance.\n\nFor each phase of the search, document:\n\n1. INTAKE & REQUIREMENTS\n   - What we got right: [Specific requirement that proved accurate]\n   - What we got wrong: [Requirement that changed, was unrealistic, or irrelevant]\n   - What we'd change: [Specific improvement to the intake process]\n   - Template update needed? Yes / No \u2014 If yes: [what to change in the Role Passport template]\n\n2. SOURCING & OUTREACH\n   - Which sourcing lane worked best? [Lane and evidence]\n   - Which outreach angle got the best response? [Angle code and reply rate]\n   - What was our biggest sourcing waste? [Where we spent time with low return]\n   - Template update needed? Yes / No \u2014 If yes: [what to change in Sourcing Blueprint or outreach templates]\n\n3. SCREENING & SUBMISSION\n   - Which screen questions were most predictive of interview success?\n   - Which questions were least useful? (Candidate always answered the same way)\n   - How accurate were our Confidence Packs? Did HM agree with our assessments?\n   - Template update needed? Yes / No \u2014 If yes: [what to change in Truth Check script or Confidence Pack format]\n\n4. INTERVIEW & CLOSE\n   - Did the interview loop produce clear signal? Where was it weakest?\n   - Was the debrief decision defensible? Any regrets?\n   - If declined: what would have changed the outcome?\n   - If accepted: what clinched it?\n\n5. THREE REUSABLE LEARNING ENTRIES\n   Each entry must be:\n   - Specific (not 'we should do better at sourcing' but 'Boolean variant 2 outperformed variant 1 by 3x on this role type')\n   - Actionable (includes what to change and where)\n   - Attributed (which stage, which template, which metric)\n\n   Learning 1: [Entry]\n   Learning 2: [Entry]\n   Learning 3: [Entry]\n\nSearch Details:\n[PASTE ROLE TITLE, OUTCOME (FILLED/UNFILLED), TIMELINE, KEY METRICS, AND ANY NOTES]",
    "usageNotes": "Complete this within 5 business days of search closure. Bring the three learning entries to Friday Proof + Learn. Update the Asset Library with any template changes. This is how the team compounds knowledge instead of repeating mistakes.",
    "tier": "Reference"
  },
  {
    "id": "12-03",
    "stage": 12,
    "stageTitle": "Postmortem & Improvement",
    "type": "verification",
    "title": "Process Improvement Validator",
    "preview": "Validate proposed process changes against data to separate real patterns from one-off reactions.",
    "content": "You are a recruiting operations quality auditor. Review the following proposed process improvements from a postmortem and validate whether each change is justified by evidence.\n\nFor each proposed change, assess:\n\n1. PATTERN OR ONE-OFF?\n   - Is this issue a recurring pattern (happened 3+ times) or a single incident?\n   - Evidence: [List the occurrences with dates and roles]\n   - If one-off: Recommend monitoring instead of process change. Set a trigger: 'If this happens again in [timeframe], then implement.'\n   - If pattern: Proceed to validation.\n\n2. ROOT CAUSE VERIFIED?\n   - Does the proposed change address the actual root cause, or just the symptom?\n   - Example of symptom fix: 'Add more screening questions' when the real issue was unclear requirements\n   - Example of root cause fix: 'Add a calibration step to intake' because requirements were ambiguous\n   - If addressing a symptom: Recommend the root cause fix instead.\n\n3. EVIDENCE-BASED?\n   - Is the change supported by measurable data? (Rejection rates, time-to-fill, conversion rates, reply rates)\n   - Or is it based on anecdote and feeling? ('It felt like we were doing too many screens')\n   - If no data: Recommend a measurement period before implementing. 'Track [metric] for [timeframe] to confirm.'\n\n4. IMPACT PROPORTIONAL?\n   - Is the change proportional to the problem?\n   - Will it add process overhead that outweighs the benefit?\n   - Is there a simpler fix that achieves the same outcome?\n\n5. VERDICT FOR EACH CHANGE\n   Rate: Implement Now / Monitor First / Reject / Modify\n   - Implement Now: Pattern confirmed, root cause addressed, evidence supports it\n   - Monitor First: Plausible but insufficient evidence, set a trigger and timeline\n   - Reject: One-off reaction, symptom-level fix, or disproportionate overhead\n   - Modify: Right direction but needs adjustment \u2014 provide specific modification\n\nProposed Process Improvements:\n[PASTE THE PROPOSED CHANGES FROM THE POSTMORTEM]\n\nSupporting Data:\n[PASTE ANY METRICS, PIPELINE DATA, OR HISTORICAL COMPARISONS]",
    "usageNotes": "Run this on every proposed process change before implementing it. Most process bloat comes from over-reacting to single incidents. This prompt separates real improvements from knee-jerk reactions. Share the verdict in the monthly postmortem.",
    "tier": "Reference"
  },
  {
    "id": "12-04",
    "stage": 12,
    "stageTitle": "Postmortem & Improvement",
    "type": "feedback",
    "title": "Feedback Loop Trigger Generator",
    "preview": "Turn postmortem data into specific update triggers for Role Passports, Sourcing Blueprints, Screen Rubrics, and Outreach Angles.",
    "content": "You are a recruiting operations analyst specializing in continuous improvement. Your job is to close the feedback loop \u2014 turning postmortem data into specific, actionable updates to upstream recruiting tools.\n\nI will provide you with:\n- Monthly telemetry data (metrics, outcomes, decline reasons)\n- Friday Ritual wins and misses\n- Postmortem reflections\n- Roles completed or lost this period\n\nFor each data source, generate SPECIFIC UPDATE TRIGGERS for these 4 upstream stages:\n\n## 1. ROLE PASSPORT UPDATES (Stage 1)\n- Which must-haves proved unnecessary? (Candidates passed without them)\n- Which missing criteria caused late-stage failure? (Should become must-haves)\n- Which dealbreakers were too strict or too loose?\n- Were compensation ranges accurate? If not, what should they be?\n- TRIGGER: \"Update Role Passport template to [specific change] because [evidence]\"\n\n## 2. SOURCING BLUEPRINT UPDATES (Stage 4)\n- Which sourcing channels produced hires vs noise?\n- Which target companies yielded strong candidates?\n- Which adjacent industries or bridge profiles worked?\n- Were Boolean strings too broad or too narrow?\n- TRIGGER: \"Update Sourcing Blueprint to [specific change] because [evidence]\"\n\n## 3. SCREEN RUBRIC UPDATES (Stage 6)\n- Which Truth Check questions produced real signal vs noise?\n- Were any strong candidates incorrectly flagged as Risk? (False positives)\n- Were any weak candidates incorrectly passed as Strong? (False negatives)\n- Which evidence requirements were most predictive of success?\n- TRIGGER: \"Update Truth Check rubric to [specific change] because [evidence]\"\n\n## 4. OUTREACH ANGLE UPDATES (Stage 5)\n- Which angle codes had highest reply rates? (Mission / Craft / Career)\n- Which messaging resonated by seniority level or market?\n- Which follow-up sequences converted vs annoyed?\n- Do decline reasons suggest messaging mismatch? (Candidates surprised by role reality)\n- TRIGGER: \"Update Outreach angles to [specific change] because [evidence]\"\n\n## OUTPUT FORMAT\nFor each trigger, provide:\n- UPDATE TARGET: [Stage and tool name]\n- CHANGE: [Specific modification]\n- EVIDENCE: [Data point or pattern that justifies this]\n- PRIORITY: High (recurring pattern, 3+ occurrences) / Medium (emerging pattern, 2 occurrences) / Low (single data point, monitor)\n\nHere is the postmortem data:\n[PASTE MONTHLY TELEMETRY SUMMARY, RITUAL WINS/MISSES, AND POSTMORTEM NOTES]",
    "usageNotes": "Run this monthly after completing the autopsy. This is the prompt that closes the loop \u2014 it turns raw postmortem data into specific updates for your upstream tools. Share the triggers with your team and assign owners. The Telemetry autopsy now auto-pulls ritual data, so paste the full summary from there.",
    "tier": "Reference"
  },
  {
    "id": "6-04",
    "stage": 6,
    "stageTitle": "Screening & Truth Check",
    "type": "calibration",
    "title": "Cross-Recruiter Calibration Exercise",
    "preview": "Run a calibration session to ensure all team members score candidates consistently using the Strong/OK/Risk framework.",
    "content": "You are a recruiting team calibration facilitator. Your job is to run a structured calibration exercise that surfaces scoring inconsistencies between team members.\n\nI will provide you with:\n- A candidate profile (real or anonymized)\n- Scoring from 2+ recruiters using the Strong/OK/Risk framework\n- The role requirements and must-haves\n\nRun this calibration protocol:\n\n## STEP 1: INDEPENDENT SCORING\nPresent the candidate profile and ask each recruiter to independently score:\n- Overall: Strong / OK / Risk\n- Each must-have: Evidence Present (Strong) / Partial (OK) / Missing (Risk)\n- Red flags identified (if any)\n- Confidence level in their scoring (High / Medium / Low)\n\n## STEP 2: REVEAL & COMPARE\nShow all scores side by side. For each disagreement, identify:\n- WHERE they disagree (which specific must-have or overall rating)\n- WHY they disagree (different interpretation of evidence, different standards, different weighting)\n- WHAT the gap is (Strong vs Risk = critical gap, Strong vs OK = minor gap)\n\n## STEP 3: ROOT CAUSE ANALYSIS\nFor each scoring disagreement, determine the root cause:\n\n1. DEFINITION GAP: Recruiters define 'Strong evidence' differently\n   - Fix: Write explicit scoring anchors with examples for each rating\n   - Example: 'Strong on Java = 5+ years commercial Java in production, not just coursework'\n\n2. WEIGHTING GAP: Recruiters weight must-haves differently\n   - Fix: Rank must-haves by priority (P1 = absolute, P2 = strong preference, P3 = nice-to-have)\n   - Rule: P1 must-haves require Strong evidence. P2 allows OK. P3 can be Risk.\n\n3. EVIDENCE INTERPRETATION GAP: Same evidence, different conclusions\n   - Fix: Create evidence examples for each rating level\n   - Example: 'Team leadership: Strong = managed 5+ people, OK = led projects but no reports, Risk = only individual contributor'\n\n4. THRESHOLD GAP: Different bar for passing\n   - Fix: Set explicit pass criteria: 'Candidate must score Strong on at least 3 of 5 must-haves and no Risk on any P1'\n\n5. BIAS GAP: Unconscious biases affecting scoring\n   - Check: Is scoring consistent across candidate demographics?\n   - Check: Does halo effect from one strong area inflate other scores?\n   - Check: Does similarity bias favor candidates like the scorer?\n\n## STEP 4: CALIBRATE\nFor each root cause identified, produce a CALIBRATION RULE:\n- Rule: [Clear, specific statement]\n- Applies to: [Which scoring dimension]\n- Example Strong: [Concrete example]\n- Example OK: [Concrete example]\n- Example Risk: [Concrete example]\n\n## STEP 5: RE-SCORE\nHave all recruiters re-score the same candidate using the new calibration rules.\nReport: Did scores converge? Where do gaps remain?\n\nCandidate Profile:\n[PASTE CANDIDATE PROFILE \u2014 CV SUMMARY, INTERVIEW NOTES, OR TRUTH CHECK OUTPUT]\n\nRecruiter Scores:\n[PASTE EACH RECRUITER'S INDEPENDENT SCORING]\n\nRole Requirements:\n[PASTE MUST-HAVES AND DEALBREAKERS FROM THE ROLE PASSPORT]",
    "usageNotes": "Run this exercise monthly with your team using a real (anonymized) candidate that generated disagreement. It takes 20 minutes and should be part of the Wednesday Pipeline Truth Check ritual. The goal is not to agree \u2014 it is to understand why you disagree and create shared scoring language. Check the Team Intel tab in Telemetry for calibration alerts that flag when TC Catch Rates differ across teams.",
    "tier": "Reference"
  },
  {
    "id": "6-05",
    "stage": 6,
    "stageTitle": "Recruiter Screen",
    "type": "execution",
    "title": "Screen Rejection Writer",
    "preview": "Draft empathetic, specific rejection messages for candidates not advancing after recruiter screen.",
    "content": "You are a recruiting communications specialist. Write a REJECTION MESSAGE for a candidate who is not advancing past the recruiter screen. The message must be professional, empathetic, and specific enough to preserve the candidate's dignity and your employer brand.\n\nInputs:\n- Candidate name\n- Role title\n- Primary reason for not advancing (do NOT include this in the message \u2014 use it to inform tone)\n- Any specific strengths worth acknowledging\n\nGenerate TWO versions:\n\n## VERSION 1: STANDARD REJECTION (Email)\nStructure:\n1. Thank them for their time and interest (1 sentence, genuine, not generic)\n2. Decision: We will not be moving forward for this specific role (clear, direct, no ambiguity)\n3. Specific positive: One genuine strength you observed during the screen (not flattery \u2014 real evidence)\n4. Forward-looking: Where their profile might be a stronger fit, or encouragement to apply for future roles\n5. Close: Warm, professional, leaves the door open\n\nRules:\n- Under 150 words\n- No corporate jargon ('after careful consideration', 'we regret to inform you')\n- No false hope ('we will keep your resume on file' unless you actually will)\n- No reasons that could create legal risk\n- Sound like a person, not a template\n\n## VERSION 2: WARM REJECTION (For strong candidates who missed on one thing)\nFor candidates you genuinely liked but who had a specific gap:\n1. Acknowledge their strength explicitly\n2. Be honest that this specific role was not the right match (without detailing why)\n3. Offer to stay connected for future roles that align better\n4. Provide one piece of actionable career advice if appropriate\n\nRules:\n- Under 200 words\n- This person might be a hire for a different role \u2014 treat them accordingly\n- If they are a silver medalist, flag them for the Silver Medalist Tracker\n\n## TIMING GUIDELINES\n- Send within 48 hours of the decision\n- Never on a Friday afternoon\n- Never batch rejections \u2014 each message should feel individual\n\nCandidate Details:\n[PASTE CANDIDATE NAME, ROLE, AND SCREEN NOTES]",
    "usageNotes": "Use this for every candidate you reject after a screen. Candidate experience is employer brand. A well-written rejection today is a referral source tomorrow. Personalize at least one line per candidate \u2014 the template is your starting point, not your final draft.",
    "tier": "Reference"
  },
  {
    "id": "9-04",
    "stage": 9,
    "stageTitle": "Debrief & Decision",
    "type": "execution",
    "title": "Post-Interview Feedback Writer",
    "preview": "Compose post-interview rejection messages with specific, growth-oriented feedback for candidates.",
    "content": "You are a recruiting communications specialist. Write a POST-INTERVIEW REJECTION message for a candidate who interviewed but will not receive an offer. This candidate invested significant time \u2014 the rejection must reflect that investment.\n\nInputs:\n- Candidate name\n- Role title\n- Number of interview rounds completed\n- Decision summary from debrief (internal \u2014 do NOT share raw debrief notes)\n- Strengths observed across interviews\n- Whether you want to provide specific feedback (not all companies do \u2014 check your policy)\n\nGenerate THREE versions:\n\n## VERSION 1: STANDARD POST-INTERVIEW REJECTION\nStructure:\n1. Acknowledge their investment: Reference the time and effort they put in (specific: 'Thank you for the [X] hours you spent with our team across [N] conversations')\n2. Decision: Clear and direct. Do not bury the lead.\n3. Strengths: 2-3 specific things the interview panel observed and valued\n4. Decision framing: 'We chose to move forward with a candidate whose experience more closely aligned with [general area]' \u2014 honest but non-specific\n5. Future: Genuine offer to stay connected if appropriate\n6. Close: Warm, respectful\n\nRules:\n- Under 200 words\n- Acknowledge the interview stages they completed\n- Do not provide scoring details or interviewer feedback directly\n- Do not compare them to other candidates explicitly\n\n## VERSION 2: FEEDBACK-INCLUSIVE REJECTION\nFor candidates who requested feedback or when your policy allows it:\n1. Everything from Version 1\n2. Add: 1-2 pieces of actionable, growth-oriented feedback\n   - Frame as development areas, not deficiencies\n   - Be specific: 'The panel felt your system design answers would benefit from more discussion of trade-offs and scaling considerations' vs. 'Your technical skills need work'\n   - Only include feedback that the candidate can act on\n3. Close with encouragement\n\nRules:\n- Feedback must be based on interview evidence, not vibes\n- Never reference bias-adjacent observations (communication style, cultural fit)\n- Each feedback point must pass the test: 'Would I be comfortable if this was screenshotted and shared on LinkedIn?'\n\n## VERSION 3: SILVER MEDALIST REJECTION\nFor candidates who were strong but lost to a slightly stronger candidate:\n1. Make it clear they were genuinely considered\n2. Be transparent: 'You were among our top candidates and the decision was difficult'\n3. Proactive offer: 'If another role at [level/function] opens in the next [timeframe], I would like to reach out directly \u2014 would that be welcome?'\n4. Ask permission to stay in touch\n\nRules:\n- Only use this if it is true. Candidates can tell when it is not.\n- Log silver medalists in the Silver Medalist Tracker for future roles\n\n## TIMING GUIDELINES\n- Send within 48 hours of the debrief decision\n- Offer a phone call for candidates who completed 3+ rounds\n- Never reject via text or chat\n\nCandidate Details:\n[PASTE CANDIDATE NAME, ROLE, INTERVIEW SUMMARY, AND DEBRIEF OUTCOME]",
    "usageNotes": "Every post-interview rejection is a brand moment. Candidates who feel respected during rejection refer others, reapply for better-fit roles, and speak well of your company. This is where most recruiting teams fail \u2014 do not skip this step.",
    "tier": "Reference"
  },
  {
    "id": "4-04",
    "stage": 4,
    "stageTitle": "Sourcing Blueprint",
    "type": "verification",
    "title": "Pipeline Diversity Audit",
    "preview": "Audit the sourcing pipeline for diversity gaps, blind spots in sourcing lanes, and systemic patterns that limit candidate pool breadth.",
    "content": "You are a diversity and inclusion recruiting analyst. Your job is to audit the sourcing pipeline for a specific role and identify where the process may be inadvertently narrowing the candidate pool or introducing bias.\n\nThis is NOT about quotas or targets. It is about ensuring the sourcing strategy is designed to surface the BEST candidates from the WIDEST possible pool \u2014 and that nothing in the process systematically excludes qualified people.\n\nAudit the following:\n\n## 1. SOURCING LANE DIVERSITY\nFor each sourcing lane in the current blueprint:\n- Is the target company list concentrated in one company type/culture/geography?\n- Are title searches inadvertently excluding candidates who do the same work under different titles?\n- Are 'adjacent industry' lanes broad enough to capture non-traditional backgrounds?\n- Are emerging talent lanes looking beyond the usual pedigree signals (top-tier schools, FAANG, etc.)?\n\nFor each gap found:\n- ISSUE: [What is narrow]\n- IMPACT: [Who gets excluded]\n- FIX: [Specific sourcing adjustment]\n\n## 2. REQUIREMENT BIAS CHECK\nReview the Role Passport must-haves for requirements that may inadvertently screen out diverse candidates:\n- Years of experience requirements (do they correlate with skill, or just tenure?)\n- Degree requirements (is the degree truly necessary, or is demonstrated skill sufficient?)\n- 'Culture fit' language (what does it actually mean in observable terms?)\n- Location requirements (do they exclude candidates from underrepresented communities?)\n- Referral-heavy sourcing (referrals tend to replicate existing team demographics)\n\nFor each flag:\n- REQUIREMENT: [What it says]\n- RISK: [How it may limit diversity]\n- ALTERNATIVE: [How to assess the same capability without the limiting proxy]\n\n## 3. BOOLEAN & SEARCH BIAS\nReview Boolean strings and search criteria for bias:\n- Are searches locked to specific company names that skew toward one demographic?\n- Do keyword filters exclude non-native English speakers or different career narrative styles?\n- Are LinkedIn profile completeness filters excluding candidates who are less active on the platform?\n\n## 4. OUTREACH INCLUSIVITY\nReview outreach messages for:\n- Language that assumes a specific background or experience path\n- Gendered language or culturally specific references\n- Assumptions about motivators that may not apply universally\n- Is the value proposition framed in a way that resonates across different candidate backgrounds?\n\n## 5. PIPELINE SNAPSHOT\nIf pipeline data is available, analyze:\n- Demographic distribution at each stage (sourced \u2192 screened \u2192 submitted \u2192 interviewed \u2192 offered)\n- Drop-off patterns: Are certain groups disproportionately screened out at specific stages?\n- If drop-off is concentrated at one stage, investigate: Is it the criteria, the assessor, or the process?\n\n## OUTPUT: DIVERSITY SOURCING ACTION PLAN\nFor each issue found, provide:\n| Issue | Stage | Impact | Recommended Fix | Priority |\n| [Description] | [Which stage] | [Who is affected] | [Specific action] | High/Medium/Low |\n\nRole Passport:\n[PASTE ROLE PASSPORT]\n\nSourcing Blueprint:\n[PASTE CURRENT SOURCING PLAN]\n\nPipeline Data (if available):\n[PASTE PIPELINE NUMBERS BY STAGE]",
    "usageNotes": "Run this at the start of every search, not after the pipeline is already built. The earlier you catch sourcing blind spots, the more diverse your candidate pool will be. Re-run at the midpoint if the pipeline is homogeneous. This is verification \u2014 not virtue signaling. A wider net finds better candidates.",
    "tier": "Reference"
  },
  {
    "id": "8-04",
    "stage": 8,
    "stageTitle": "Interview Loop Design",
    "type": "verification",
    "title": "Inclusive Interview Audit",
    "preview": "Audit an interview loop for structural bias, accessibility barriers, and inclusive design before candidates enter the process.",
    "content": "You are an inclusive hiring process auditor. Review the following interview loop and identify structural elements that may disadvantage certain candidate groups \u2014 not through intent, but through design.\n\nAudit for:\n\n## 1. QUESTION BIAS\nFor each interview question in the loop:\n- Does it assume a specific career path? (e.g., 'Tell me about your time at a startup' assumes startup experience)\n- Does it favor a specific communication style? (e.g., rapid-fire questions disadvantage non-native speakers and introverts)\n- Does it test the skill, or does it test the ability to perform in a specific format? (e.g., whiteboard coding tests performance anxiety, not coding ability)\n- Can the question be answered equally well by someone with a non-traditional background?\n\nFor each issue:\n- QUESTION: [The problematic question]\n- BIAS RISK: [Who it disadvantages and why]\n- ALTERNATIVE: [A question that tests the same competency without the bias]\n\n## 2. FORMAT ACCESSIBILITY\n- Is the interview format accessible to candidates with different needs? (Hearing impairment, neurodivergence, physical disability)\n- Is there a process for candidates to request accommodations?\n- Are time limits reasonable? (Timed exercises can disadvantage candidates with anxiety or processing differences)\n- Is the interview schedule flexible enough for candidates in different time zones or with caregiving responsibilities?\n\n## 3. PANEL COMPOSITION\n- Does the interview panel represent diverse perspectives?\n- Is there at least one interviewer who is trained in structured interviewing and bias awareness?\n- Are all interviewers using structured scorecards, or are some relying on unstructured impressions?\n- Is there a risk of groupthink if all interviewers share similar backgrounds?\n\n## 4. SCORING OBJECTIVITY\n- Are scorecard anchors based on observable behaviors, not personality traits?\n- Is 'culture fit' defined in terms of values and behaviors, not personal similarity?\n- Can two interviewers reach similar scores independently? (If not, the scorecard is too subjective)\n- Are scoring decisions made independently before the debrief? (Prevents anchoring bias)\n\n## 5. CANDIDATE EXPERIENCE EQUITY\n- Does every candidate receive the same preparation information?\n- Are internal referrals or employee-connected candidates given extra context that external candidates do not receive?\n- Is the process transparent enough that a candidate with no insider knowledge can succeed equally?\n\n## OUTPUT: INCLUSIVE INTERVIEW ACTION PLAN\nFor each issue:\n| Issue | Severity | Who It Affects | Fix | Implementation |\n| [Description] | High/Medium/Low | [Group] | [Specific change] | [When and how] |\n\nRate the overall loop: Inclusive / Needs Improvement / Significant Redesign Needed\n\nInterview Loop Design:\n[PASTE THE FULL INTERVIEW LOOP PLAN]\n\nRole Passport:\n[PASTE FOR REFERENCE]",
    "usageNotes": "Run this on every interview loop before the first candidate enters. Inclusive design is not about lowering the bar \u2014 it is about removing barriers that prevent you from seeing the best candidates clearly. A biased process does not just hurt candidates \u2014 it costs you hires.",
    "tier": "Reference"
  },
  {
    "id": "10-04",
    "stage": 10,
    "stageTitle": "Offer & Close",
    "type": "execution",
    "title": "Negotiation Strategy Builder",
    "preview": "Build a structured negotiation playbook for handling counter-offers, competing offers, and term adjustments.",
    "content": "You are a senior recruiting strategist specializing in offer negotiation. Build a NEGOTIATION STRATEGY for an active negotiation scenario. This goes beyond the close plan \u2014 this is for when the candidate pushes back, has competing offers, or receives a counter.\n\n## SCENARIO ASSESSMENT\nClassify the negotiation:\n- TYPE A: Candidate wants more compensation (base, bonus, equity)\n- TYPE B: Candidate has a competing offer\n- TYPE C: Candidate received a counter-offer from current employer\n- TYPE D: Candidate wants non-comp terms adjusted (title, start date, remote, scope)\n- TYPE E: Multiple factors in play\n\n## 1. LEVERAGE ANALYSIS\n| Factor | Candidate's Leverage | Our Leverage |\n|--------|---------------------|---------------|\n| Market alternatives | [How many other options do they have?] | [How many other candidates do we have?] |\n| Urgency | [How urgently do they need to move?] | [How urgently do we need to fill?] |\n| Uniqueness | [How rare is their skill set?] | [How rare is this opportunity for them?] |\n| Information | [What do they know about our range/flexibility?] | [What do we know about their other offers?] |\n\nLeverage balance: Candidate-favored / Balanced / Company-favored\n\n## 2. NEGOTIATION BOUNDARIES\nBefore negotiating, define:\n- WALK-AWAY POINT: What is the absolute maximum we can offer? (Get pre-approval)\n- TARGET: What do we want to close at? (Leaves room for movement)\n- OPENING: What is our first counter-proposal? (Anchors the negotiation)\n- NON-NEGOTIABLES: What cannot change regardless of pressure?\n- CREATIVE LEVERS: What can we offer that costs us little but matters to them?\n  - Signing bonus (one-time cost vs. recurring salary increase)\n  - Accelerated review timeline (promise of early salary review)\n  - Title adjustment (costs nothing, means a lot to some candidates)\n  - Flexible start date\n  - Remote/hybrid flexibility\n  - Professional development budget\n  - Extra PTO days\n\n## 3. COUNTER-OFFER PLAYBOOK (Type C)\nIf the candidate receives a counter from their current employer:\n\nPRE-EMPT (before the counter arrives):\n- Script: 'Before you resign, your employer will likely make a counter-offer. Let me share what the data says about counter-offers: [70% of people who accept a counter leave within 12 months]. The reasons you want to leave will still be there \u2014 a counter just adds a higher salary to the same problems.'\n- Timing: Say this BEFORE they give notice, not after the counter lands.\n\nRESPOND (after the counter arrives):\n- Do NOT panic-match. Instead, reframe around motivators.\n- Script: 'I understand the counter is tempting. Let me ask \u2014 which of the reasons you shared with me for wanting to leave does the counter actually solve? [Reference their specific motivators from the Motivator Map].'\n- If motivators are primarily financial: Acknowledge it honestly. If we cannot match, say so and focus on total value.\n\n## 4. COMPETING OFFER PLAYBOOK (Type B)\nIf the candidate has another offer:\n- Ask: 'Can you share what you are weighing between the two? I want to help you make the best decision for your career, not just sell you on us.'\n- Map their decision criteria and show where we win.\n- Do NOT trash the competitor. Acknowledge their strengths and differentiate on substance.\n- If we lose on comp: Win on growth, team, mission, or scope.\n- If we lose on everything: Be gracious. This is a long-term relationship.\n\n## 5. COMPENSATION NEGOTIATION (Type A)\n- Rule 1: Never say 'no' \u2014 say 'here is what we can do'\n- Rule 2: If you move on base, get something in return (start date commitment, sign-on waiver)\n- Rule 3: Present total comp, not just base. Many candidates focus on base when total comp is competitive.\n- Rule 4: Use ranges, not points. 'We can get you to the $X-Y range' gives room to land.\n\n## 6. NEGOTIATION TIMELINE\n| Day | Action | Goal |\n|-----|--------|------|\n| Day 0 | Initial offer extended | Gauge reaction, listen for concerns |\n| Day 1 | Candidate pushes back | Listen fully, do not react immediately |\n| Day 2 | Internal alignment on counter | Get approvals, define boundaries |\n| Day 3 | Counter-proposal delivered | Frame around motivators, not just numbers |\n| Day 4 | Follow-up | Answer questions, address remaining concerns |\n| Day 5 | Close | Clear deadline with warmth: 'We would love your answer by Friday so we can start building your onboarding plan' |\n\nCandidate Details + Negotiation Context:\n[PASTE MOTIVATOR MAP, CURRENT OFFER TERMS, AND CANDIDATE'S PUSHBACK/COUNTER/COMPETING OFFER]",
    "usageNotes": "Build this the moment the candidate signals pushback \u2014 do not wait until the negotiation escalates. Get walk-away approval from the HM BEFORE negotiating. The worst position is promising something you cannot deliver. Share the leverage analysis with your manager if you need support.",
    "tier": "Daily"
  },
  {
    "id": "4-05",
    "stage": 4,
    "stageTitle": "Sourcing Blueprint",
    "type": "execution",
    "title": "Pipeline Contingency Planner",
    "preview": "Build a pipeline depth plan with backup lanes, silver medalist strategy, and contingency triggers for when primary candidates fall through.",
    "content": "You are a recruiting operations strategist. Build a PIPELINE CONTINGENCY PLAN that ensures you are never one candidate withdrawal away from restarting a search.\n\nFor the following role, create:\n\n## 1. PIPELINE DEPTH TARGETS\nBased on historical conversion rates (or industry benchmarks if no internal data):\n\n| Stage | Target Count | Current Count | Gap | Action if Below Target |\n|-------|-------------|---------------|-----|------------------------|\n| Sourced candidates | [N] | [Current] | [Gap] | [What to do] |\n| Contacted | [N] | [Current] | [Gap] | [What to do] |\n| Responded positively | [N] | [Current] | [Gap] | [What to do] |\n| Screened | [N] | [Current] | [Gap] | [What to do] |\n| Submitted to HM | [N] | [Current] | [Gap] | [What to do] |\n| Interviewing | [N] | [Current] | [Gap] | [What to do] |\n\nRule of thumb: For every 1 hire, you need [X] sourced (adjust based on role difficulty).\n- Easy roles (Green risk): 20:1 sourced-to-hire\n- Moderate roles (Amber risk): 40:1 sourced-to-hire\n- Difficult roles (Red risk): 80:1 sourced-to-hire\n\n## 2. BACKUP LANE STRATEGY\nIdentify 2 backup sourcing lanes that are NOT in the primary blueprint:\n\nBACKUP LANE A:\n- Source: [Where to look \u2014 different geography, adjacent role type, different seniority]\n- Activation trigger: [When to open this lane \u2014 e.g., 'If fewer than 3 screens completed by week 2']\n- Expected yield: [Realistic assessment]\n- Trade-off: [What you give up \u2014 longer ramp, less direct experience, etc.]\n\nBACKUP LANE B:\n- Source: [A fundamentally different approach \u2014 referral blitz, agency partnership, event sourcing]\n- Activation trigger: [When to open this lane]\n- Expected yield: [Realistic assessment]\n- Trade-off: [Cost, time, quality implications]\n\n## 3. SILVER MEDALIST PIPELINE\nFor candidates who are strong but do not get the offer:\n- How will you track them? [Silver Medalist Tracker in Asset Library]\n- What message will you send? [Use the Silver Medalist Rejection from prompt 9-04]\n- How long is the warm window? [Typically 3-6 months]\n- What triggers a re-engagement? [New role opens, candidate's situation changes]\n- Who owns the relationship? [Assign a specific recruiter]\n\n## 4. CONTINGENCY TRIGGERS\nDefine specific triggers that activate contingency actions:\n\n| Trigger | Threshold | Action | Owner |\n|---------|-----------|--------|-------|\n| Low response rate | Below [X]% after [N] outreach | Switch outreach angle, expand target list | Sourcer |\n| Screen drop-off | [N]+ candidates fail screen | Review must-haves with HM, possible recalibration | Recruiter |\n| HM rejection spike | 3+ submissions rejected | Emergency calibration meeting | Recruiter + HM |\n| Finalist drops out | Any finalist withdraws | Immediately activate backup lane + check silver medalists | Recruiter |\n| Offer declined | Offer rejected | Root cause analysis + activate backup pipeline within 24 hours | Recruiter |\n| Timeline overrun | [N] weeks past target without offer | Escalate to leadership with options memo | Recruiting lead |\n\n## 5. PARALLEL PIPELINE RULES\n- NEVER go single-threaded on one candidate until the offer is signed\n- Keep at least 2 candidates in active process until verbal offer accepted\n- If you have only 1 candidate in final rounds, activate backup lanes immediately\n- Track pipeline depth in weekly Telemetry and flag when below minimums\n\nRole Details:\n[PASTE ROLE PASSPORT AND CURRENT PIPELINE STATUS]\n\nHistorical Data (if available):\n[PASTE CONVERSION RATES FROM PREVIOUS SIMILAR SEARCHES]",
    "usageNotes": "Build this alongside the Sourcing Blueprint at the start of every search. Review pipeline depth in Monday Signal Kickoff. The biggest recruiting failure is not a bad hire \u2014 it is restarting a search because you had no backup when a finalist dropped out.",
    "tier": "Reference"
  },
  {
    "id": "7-04",
    "stage": 7,
    "stageTitle": "Submission & HM Prep",
    "type": "execution",
    "title": "Silver Medalist Manager",
    "preview": "Track and manage strong candidates who were not selected, keeping them warm for future roles.",
    "content": "You are a talent pipeline strategist. Manage the SILVER MEDALIST PIPELINE \u2014 strong candidates who interviewed well but were not selected for the current role. These are pre-qualified, pre-vetted candidates who can dramatically reduce time-to-fill for future roles.\n\n## 1. SILVER MEDALIST INTAKE\nFor each silver medalist, capture:\n\n| Field | Details |\n|-------|--------|\n| Candidate name | [Name] |\n| Original role | [Role they interviewed for] |\n| Date passed | [When the decision was made] |\n| Reason not selected | [Specific: lost to stronger candidate, timing, one skill gap, etc.] |\n| Strengths verified | [What the interview loop confirmed they are strong at] |\n| Development areas | [What was the gap \u2014 be specific] |\n| Suitable for | [Role types, levels, or functions where they would be a fit] |\n| Candidate sentiment | [How did they take the rejection? Open to future roles?] |\n| Warm window | [How long are they likely to be available/interested? 3/6/12 months] |\n| Relationship owner | [Which recruiter maintains contact] |\n| Last touchpoint | [Date and nature of last communication] |\n\n## 2. RE-ENGAGEMENT TRIGGERS\nAutomatically flag silver medalists when:\n- A new role opens that matches their 'suitable for' profile\n- Their warm window is approaching expiry (send a check-in)\n- They update their LinkedIn profile (signals they may be looking)\n- A role they were previously considered for reopens\n- 90 days have passed since last touchpoint\n\n## 3. RE-ENGAGEMENT MESSAGES\nGenerate personalized re-engagement messages based on context:\n\nSCENARIO A: New role opened that matches their profile\n- Reference the previous interaction positively\n- Explain why this new role might be a better fit\n- Make it easy: 'No need to re-apply \u2014 I have your interview feedback on file. Would a 15-minute call to discuss this role work?'\n\nSCENARIO B: Check-in (no specific role)\n- Warm, genuine check-in on their career\n- Share something of value (industry insight, market data, company news)\n- Keep the door open without pressure\n\nSCENARIO C: Previous role reopened\n- Be honest: 'The role you interviewed for has reopened due to [reason, if shareable].'\n- Acknowledge their previous interview performance\n- Explain what, if anything, has changed about the role\n\n## 4. SILVER MEDALIST METRICS\nTrack:\n- Total silver medalists in pipeline by function/level\n- Re-engagement response rate\n- Silver medalist-to-hire conversion rate\n- Average time from silver medalist to hire (vs. fresh candidate)\n- Cost savings: avoided sourcing hours + faster time-to-fill\n\n## 5. PIPELINE HYGIENE\n- Review silver medalist pipeline monthly\n- Remove candidates who have moved to new roles and are no longer available\n- Update 'suitable for' profiles based on new role openings\n- Merge with new search pipelines when roles match\n\nSilver Medalist Details:\n[PASTE CANDIDATE NAME, ORIGINAL ROLE, INTERVIEW OUTCOME, AND STRENGTHS/GAPS]",
    "usageNotes": "Every strong candidate you reject is a future pipeline asset \u2014 but only if you track them. Add silver medalists the same day you send the rejection. Review the silver medalist pipeline before opening any new sourcing effort. The fastest hire is the one you already vetted.",
    "tier": "Reference"
  },
  {
    "id": "7-05",
    "stage": 7,
    "stageTitle": "Submission & HM Prep",
    "type": "verification",
    "title": "Confidence Pack Quality Audit",
    "preview": "Manager or peer review of Confidence Packs for evidence quality, risk calibration accuracy, and cross-team consistency.",
    "content": "You are a recruiting quality manager. Your job is to audit Confidence Packs produced by your team \u2014 not to second-guess decisions, but to verify that the verification is actually happening. This is the meta-layer: checking that the system is working, not just trusting that it is.\n\nI will provide you with 2-5 Confidence Packs from the same team or the same recruiter. Review them for quality, consistency, and calibration.\n\n## 1. EVIDENCE QUALITY AUDIT\nFor each Confidence Pack, score these dimensions:\n\n| Dimension | Score (1-5) | Notes |\n|-----------|-------------|-------|\n| Evidence specificity | [1=vague, 5=concrete with quotes] | [What's missing?] |\n| Must-have coverage | [1=gaps, 5=all addressed] | [Which must-haves lack evidence?] |\n| Risk transparency | [1=risks hidden/minimized, 5=risks clearly stated with mitigations] | [Are risks real or performative?] |\n| Interpretation separation | [1=evidence and opinion mixed, 5=clearly separated] | [Where does opinion masquerade as evidence?] |\n| Actionability | [1=HM gets no clear next step, 5=HM knows exactly what to do] | [Is the recommended next step specific?] |\n\nOverall CP Quality: Strong / Adequate / Needs Improvement\n\n## 2. RISK CALIBRATION CHECK\nReview the risk sections across all submitted CPs:\n\n**Are risks too conservative?**\n- Are common, low-impact risks flagged as major concerns? (e.g., 'candidate has only 4 years instead of 5')\n- Is the recruiter hedging by flagging everything, diluting real risk signals?\n- Would this level of risk-flagging cause a hiring manager to reject candidates who should advance?\n\n**Are risks too lenient?**\n- Are genuine red flags being minimized or omitted?\n- Are mitigations realistic, or are they wishful thinking? ('We can coach them on X' \u2014 can you really?)\n- Would this level of risk tolerance lead to regret hires?\n\n**Risk calibration verdict:** Too Conservative / Well Calibrated / Too Lenient\n**Specific feedback:** [What to adjust and how]\n\n## 3. CONSISTENCY CHECK (Cross-CP Comparison)\nCompare the CPs side by side:\n\n- **Evidence bar consistency:** Is the same standard of evidence applied to all candidates, or do some get a pass while others are held to a higher bar?\n- **Risk treatment consistency:** Are similar risks flagged the same way across candidates, or does risk tolerance vary by candidate?\n- **Scoring language consistency:** Do 'Strong evidence' and 'Risk' mean the same thing across CPs?\n- **Format consistency:** Do all CPs follow the same structure, or is quality variable?\n\nConsistency verdict: Consistent / Minor Drift / Significant Inconsistency\n\n## 4. FEEDBACK FOR THE RECRUITER\nFor each CP, provide:\n- **Keep doing:** [What is working well \u2014 be specific]\n- **Adjust:** [What needs to change \u2014 with an example of how to improve it]\n- **Stop doing:** [Any anti-patterns observed]\n\n## 5. TEAM-LEVEL PATTERNS\nIf reviewing CPs from multiple recruiters:\n- Are there systematic patterns? (Everyone minimizes risk, everyone over-flags constraints, etc.)\n- Do certain must-have types consistently lack evidence across the team?\n- Is there a team-wide calibration issue that needs a group session?\n- Recommendation: [Individual coaching / Team calibration session / Process change needed]\n\nConfidence Packs to Review:\n[PASTE 2-5 CONFIDENCE PACKS]",
    "usageNotes": "Run this monthly with your team lead or manager. Pick 3-5 CPs from the past month \u2014 mix of advances and passes. The goal is not to overrule decisions, but to ensure the quality of the verification process itself. If risk calibration is off, run a calibration exercise (prompt 6-04) with the team.",
    "tier": "Reference"
  },
  {
    "id": "7-06",
    "stage": 7,
    "stageTitle": "Submission & HM Prep",
    "type": "verification",
    "title": "Evidence Chain Builder",
    "preview": "Map every Confidence Pack claim back to its source in the Role Passport and Truth Check, creating an auditable evidence chain.",
    "content": "You are a recruiting evidence auditor. Your job is to create an EVIDENCE CHAIN \u2014 a traceable link from every claim in a Confidence Pack back to its source in the Role Passport (must-haves) and the Truth Check (screening evidence).\n\nThis is the cross-stage citation that makes the verification system auditable. Without it, the CP is just a persuasive document. With it, it is a defensible one.\n\n## INPUTS NEEDED\n1. The Role Passport (must-haves, dealbreakers, evidence requirements)\n2. The Truth Check output (screen notes, scoring, evidence captured)\n3. The Confidence Pack (the submission document)\n\n## BUILD THE EVIDENCE CHAIN\n\nFor each claim in the Confidence Pack, trace it:\n\n### MATCH CLAIMS (\"Why This Candidate\")\n\n| CP Claim | Passport Source | TC Evidence | Chain Status |\n|----------|----------------|-------------|-------------|\n| [Match reason 1 from CP] | [Which must-have does this address? Quote the exact requirement] | [What TC question produced this evidence? What did the candidate say? What was the score?] | Complete / Partial / Broken |\n| [Match reason 2 from CP] | [Must-have source] | [TC evidence source] | Complete / Partial / Broken |\n| [Match reason 3 from CP] | [Must-have source] | [TC evidence source] | Complete / Partial / Broken |\n\n**Chain Status Definitions:**\n- **Complete:** CP claim traces directly to a Passport must-have AND is supported by specific TC evidence with Strong or OK score\n- **Partial:** CP claim addresses a must-have but TC evidence is weak, incomplete, or scored as Risk\n- **Broken:** CP claim cannot be traced to a Passport must-have, or no TC evidence supports it\n\n### RISK CLAIMS\n\n| CP Risk | TC Source | Mitigation Realistic? |\n|---------|-----------|----------------------|\n| [Risk stated in CP] | [Where was this risk identified? TC score? Follow-up probes?] | [Is the proposed mitigation based on evidence or hope?] |\n\n### MISSING COVERAGE\n\n| Passport Must-Have | In CP? | In TC? | Gap |\n|-------------------|--------|--------|-----|\n| [Must-have 1] | Yes / No | Yes / No | [What's missing and why] |\n| [Must-have 2] | Yes / No | Yes / No | [What's missing and why] |\n| [Must-have 3] | Yes / No | Yes / No | [What's missing and why] |\n\n## EVIDENCE CHAIN SCORE\n\nRate the overall chain:\n- **All chains complete, all must-haves covered:** SUBMIT \u2014 Evidence is traceable and defensible\n- **1-2 partial chains, no broken chains:** SUBMIT WITH NOTES \u2014 Flag partial chains to HM\n- **Any broken chain or must-have not covered:** HOLD \u2014 Gather missing evidence before submission\n\n## RECOMMENDATIONS\n- For each broken or partial chain: [Specific action to close the gap]\n- For must-haves not covered: [Go back to TC or schedule a follow-up call]\n- For risks without TC evidence: [What additional validation is needed]\n\nRole Passport:\n[PASTE ROLE PASSPORT]\n\nTruth Check Output:\n[PASTE TRUTH CHECK RESULTS / SCREEN NOTES]\n\nConfidence Pack:\n[PASTE THE CONFIDENCE PACK DRAFT]",
    "usageNotes": "Run this before finalizing any Confidence Pack. It takes 5 minutes and transforms your CP from 'a good writeup' into 'a defensible evidence document.' If the chain has breaks, fix them before submitting \u2014 a CP with broken evidence chains erodes HM trust faster than no CP at all.",
    "tier": "Reference"
  }
]
